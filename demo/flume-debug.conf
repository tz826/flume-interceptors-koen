a1.sources = r1
a1.channels = c1
a1.sinks=k1

#channel
a1.channels.c1.type = memory
a1.channels.c1.capacity = 100000
a1.channels.c1.transactionCapacity = 10

#connection
a1.sources.r1.channels = c1
a1.sinks.k1.channel = c1

#source
a1.sources.r1.type=spooldir
a1.sources.r1.spoolDir=/flume-debug-data
a1.sources.r1.recursiveDirectorySearch=TRUE
a1.sources.r1.deserializer.maxLineLength=10485760
a1.sources.r1.batchsize=1
a1.sources.r1.fileHeader = true

a1.sources.r1.interceptors=i1 i2 i3 i4
#a1.sources.r1.interceptors.i1.type=REGEX_EXTRACTOR
#a1.sources.r1.interceptors.i1.regex =([^\\s]*)\t([^\\s]*)\t([^\\s]*)\t([^\\s]*)\t([^\\s]*)\t([^\\s]*)\t([^\\s]*)\t([^\\s]*)\t([^.*]*)
##[INFO]	  [201531]        [111-1142-5385]      [trait] [563c633f0cf2009669d2fd08]        [创造能力]   [rs1800955]  [--]      [2017-04-01 11:44:51]
#a1.sources.r1.interceptors.i1.serializers = s1 s2 s3 s4 s5 s6 s7 s8 s9
#a1.sources.r1.interceptors.i1.serializers.s1.name = type
#a1.sources.r1.interceptors.i1.serializers.s2.name = productId
#a1.sources.r1.interceptors.i1.serializers.s3.name = barCode
#a1.sources.r1.interceptors.i1.serializers.s4.name = product
#a1.sources.r1.interceptors.i1.serializers.s5.name = id
#a1.sources.r1.interceptors.i1.serializers.s6.name = name
#a1.sources.r1.interceptors.i1.serializers.s7.name = rId
#a1.sources.r1.interceptors.i1.serializers.s8.name = type_new
#a1.sources.r1.interceptors.i1.serializers.s9.name = dateTime

a1.sources.r1.interceptors = i1
a1.sources.r1.interceptors.i1.type = com.tsm.flume.interceptor.json.JsonInterceptor$Builder
a1.sources.r1.interceptors.i1.name = logtime_timestamp
a1.sources.r1.interceptors.i1.jsonpath = $.logtime
a1.sources.r1.interceptors.i1.serializers = dt
a1.sources.r1.interceptors.i1.serializers.dt.type=com.tsm.flume.interceptor.json.JsonInterceptorDateStrSerializer
a1.sources.r1.interceptors.i1.serializers.dt.pattern=yyyy-MM-dd'T'HH:mm:ssZ
a1.sources.r1.interceptors.i1.serializers.dt.patternTarget=yyyy-MM-dd
a1.sources.r1.interceptors.i1.serializers.dt.name=timestamp

#在event的header中添加一个key叫：timestamp,value为当前的时间戳
a1.sources.r1.interceptors.i2.type=org.apache.flume.interceptor.TimestampInterceptor$Builder  

#在event的header中添加一个key叫：host,value为当前机器的hostname或者ip  
a1.sources.r1.interceptors.i3.type=org.apache.flume.interceptor.HostInterceptor$Builder  
a1.sources.r1.interceptors.i3.hostHeader = host

a1.sources.r1.interceptors.i4.type = static
a1.sources.r1.interceptors.i4.preserveExisting = true
a1.sources.r1.interceptors.i4.key = nickname
a1.sources.r1.interceptors.i4.value = koen

#sink
a1.channels = c1
a1.sinks = k1
a1.sinks.k1.type = logger
a1.sinks.k1.channel = c1


#sink
#a1.sinks.k1.type=com.cognitree.flume.sink.elasticsearch.ElasticSearchSink
#a1.sinks.k1.es.bulkActions=5
#a1.sinks.k1.es.bulkProcessor.name=bulkprocessor
#a1.sinks.k1.es.bulkSize=5
#a1.sinks.k1.es.bulkSize.unit=MB
#a1.sinks.k1.es.concurrent.request=1
#a1.sinks.k1.es.flush.interval.time=5m
#a1.sinks.k1.es.backoff.policy.time.interval=50M
#a1.sinks.k1.es.backoff.policy.retries=8
#a1.sinks.k1.es.cluster.name=es
#a1.sinks.k1.es.client.hosts=localhost:9300
#a1.sinks.k1.es.index=regex_log
#a1.sinks.k1.es.type=log
#a1.sinks.k1.es.index.builder=com.cognitree.flume.sink.elasticsearch.HeaderBasedIndexBuilder
#a1.sinks.k1.es.serializer=com.cognitree.flume.sink.elasticsearch.SimpleSerializer
#a1.sinks.k1.es.serializer.csv.fields=id:int,name:string,isemployee:boolean,leaves:float
#a1.sinks.k1.es.serializer.csv.delimiter=,
#a1.sinks.k1.es.serializer.avro.schema.file=/usr/local/schema.avsc
